{"cells":[{"cell_type":"markdown","metadata":{"id":"VCmkTU9Ypwv3"},"source":["### Tracing\n","\n","Tracing is an export technique that runs our model with certain inputs and traces or records all operations executed into the model's graph.\n","\n","The API can be simply used as torch.jit.trace(model, input).\n","\n","A model is called \"traceable\" if torch.jit.trace(model, input) succeeds for standard input.\n","\n","A simple example of tracing in PyTorch follows. Here we first define a custom model class and then instantiate it. We then trace the model instance by passing some sample inputs to it, like so -"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7351,"status":"ok","timestamp":1690080262204,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"GAA20pUHoVjP","outputId":"2d016131-d91a-4bc9-f6a5-0e98727a790e"},"outputs":[{"name":"stdout","output_type":"stream","text":["MyModel(\n","  original_name=MyModel\n","  (linear): Linear(original_name=Linear)\n",")\n"]},{"data":{"text/plain":["(tensor([[-0.4162,  0.9441,  0.8803,  0.5506],\n","         [-0.0428,  0.8970,  0.8539,  0.7946],\n","         [-0.3904,  0.8450,  0.0802,  0.6143]], grad_fn=\u003cTanhBackward0\u003e),\n"," tensor([[-0.4162,  0.9441,  0.8803,  0.5506],\n","         [-0.0428,  0.8970,  0.8539,  0.7946],\n","         [-0.3904,  0.8450,  0.0802,  0.6143]], grad_fn=\u003cTanhBackward0\u003e))"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","class MyModel(torch.nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.linear = torch.nn.Linear(4, 4)\n","\n","    def forward(self, x, h):\n","        new_h = torch.tanh(self.linear(x) + h)\n","        return new_h, new_h\n","\n","net = MyModel() #PYTorch model. -\u003e nn.Module.\n","x, h = torch.rand(3, 4), torch.rand(3, 4)\n","traced_net = torch.jit.trace(net, (x, h)) #Invoke to create ScriptModule. torch.jit.ScriptModule\n","print(traced_net)\n","traced_net(x, h)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1690080280149,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"kcX3MDpHoZMX"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"SZM60XhUp47-"},"source":["During tracing, the Python code is automatically converted into the subset (TorchScript) of Python by recording only the actual operators on tensors and simply executing and discarding the other surrounding Python code.\n","\n","* torch.jit.trace invokes the Module, records the computations that occur when the Module was run on the inputs, and then creates an instance of the torch.jit.ScriptModule, essentially code written in plain Python converted to the TorchScript mode.\n","\n","TorchScript also records the model definitions in what is called an Intermediate Representation (or IR) or a graph that we can access with the .graph property of the traced model, like so -"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690080280671,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"LCsKYxlRoaM8","outputId":"5e35d2cf-1ce6-431c-de77-1deba5e3be2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["graph(%self.1 : __torch__.MyModel,\n","      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n","      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n","  %linear : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n","  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n","  %11 : int = prim::Constant[value=1]() # \u003cipython-input-2-ff2b47965842\u003e:8:0\n","  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%20, %h, %11) # \u003cipython-input-2-ff2b47965842\u003e:8:0\n","  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%12) # \u003cipython-input-2-ff2b47965842\u003e:8:0\n","  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%13, %13)\n","  return (%14)\n","\n"]}],"source":["print(traced_net.graph)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690080281974,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"2yagCIzQob91","outputId":"5905732d-9fd6-4f4d-fc2f-02fb0e830793"},"outputs":[{"name":"stdout","output_type":"stream","text":["def forward(self,\n","    x: Tensor,\n","    h: Tensor) -\u003e Tuple[Tensor, Tensor]:\n","  linear = self.linear\n","  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n","  return (_0, _0)\n","\n"]}],"source":["print(traced_net.code)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690080309011,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"O27Bis3Poduc"},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([[ 0.3966, -0.0609,  0.7879,  0.7994],\n","        [ 0.3194, -0.1219,  0.6428,  0.9492],\n","        [ 0.7625, -0.1400, -0.1661,  0.8294]],\n","       grad_fn=\u003cDifferentiableGraphBackward\u003e), tensor([[ 0.3966, -0.0609,  0.7879,  0.7994],\n","        [ 0.3194, -0.1219,  0.6428,  0.9492],\n","        [ 0.7625, -0.1400, -0.1661,  0.8294]],\n","       grad_fn=\u003cDifferentiableGraphBackward\u003e))\n"]}],"source":["\n","print(traced_net(x, h))\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1690080284151,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"8JCiVD_YoiPb"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5tIVvjWdp84N"},"source":["Scripting\n","The second way of converting PyTorch modules to TorchScript format is scripting, which can be used with the torch.jit.script API.\n","\n","With scripting, we can write our code directly in TorchScript mode introducing a certain level of verbosity. The support offered by the scripting technique is much wider than that offered by the tracing technique.\n","\n","A simple example demonstrating scripting and also why scripting might be required over tracing is as follows -"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7fmVAmkjp9g3"},"outputs":[{"name":"stdout","output_type":"stream","text":["def forward(self,\n","    argument_1: Tensor) -\u003e NoneType:\n","  return None\n","\n"]},{"name":"stderr","output_type":"stream","text":["\u003cipython-input-10-22bfb7728c3f\u003e:4: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if x.sum() \u003e 0:\n"]}],"source":["import torch\n","class DecisionGate(torch.nn.Module):\n","    def forward(self, x):\n","        if x.sum() \u003e 0:\n","            return x\n","        else:\n","            return -x\n","\n","class Model(torch.nn.Module):\n","    def __init__(self, dg):\n","        super(Model, self).__init__()\n","        self.dg = dg\n","        self.linear = torch.nn.Linear(4, 4)\n","\n","    def forward(self, x, h):\n","        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n","        return new_h, new_h\n","\n","net = Model(DecisionGate())\n","traced_net = torch.jit.trace(net, (x, h))\n","\n","print(traced_net.dg.code)\n","# print(traced_net.code)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8oEXEZfqOIV"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bAsiDVZ5qOzb"},"source":["As can be seen in the warning produced in the output from the above code that attempts tracing, the control flow was totally erased in the traced model and hence the IR is incorrect. This happened because of how the tracing technique functions - it runs the model code, records the operations \"that happen\" and then constructs a ScriptModule that does just that and hence removes operations like control flow.\n","\n","To get around this, we have scripting that directly analyzes our models written in Python source code to transform it into TorchScript mode.\n","\n","The following code shows how scripting captured the model graph correctly."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1690080685085,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"qbg50IWQqDBc","outputId":"ebccc57a-c38e-4cf8-c733-f1fb83ad150e"},"outputs":[{"name":"stdout","output_type":"stream","text":["def forward(self,\n","    x: Tensor) -\u003e Tensor:\n","  if bool(torch.gt(torch.sum(x), 0)):\n","    _0 = x\n","  else:\n","    _0 = torch.neg(x)\n","  return _0\n","\n","def forward(self,\n","    x: Tensor,\n","    h: Tensor) -\u003e Tuple[Tensor, Tensor]:\n","  dg = self.dg\n","  linear = self.linear\n","  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n","  new_h = torch.tanh(_0)\n","  return (new_h, new_h)\n","\n"]}],"source":["scripted_gate = torch.jit.script(DecisionGate())\n","\n","net = Model(scripted_gate)\n","scripted_net = torch.jit.script(net)\n","\n","print(scripted_gate.code)\n","print(scripted_net.code)\n"]},{"cell_type":"markdown","metadata":{"id":"MA_WtU0NqSSU"},"source":["Difference Between Scripting and Tracing\n","In this section, we will detail the major points that differentiate the two techniques to convert PyTorch modules to the TorchScript` format - the tracing and the scripting techniques- from each other and highlight the benefits of using one over the other.\n","\n","\n","\n","*   Tracing lets us use the dynamic tensor ops in Python as it records tensor operations. It cannot trace control flow, data structures, or Python constructs.\n","*  On the other hand, scripting, with some code changes, supports all of the features that are compatible with the JIT compiler, a full list of which can be found here. In addition, it preserves the Python control flow and offers wider support for data structures like lists or dictionaries.\n","* The generalizability of traced models needs to be ensured explicitly, while scripted models are always generalizable.\n","\n","* Although scripting is a good way to support advanced graphs containing control flow etc., there are a plethora of things that are not supported by the JIT compiler, like classes, builtins like range and zip, dynamic types, etc. hence it limits us in our ability to use abstract types and advanced features of python as a programming language which eventually means that our code can get messy more often than not.\n","\n","In any case, for Scripting and Tracing to work properly, the model must be a connected graph representable in the TorchScript format."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690080767173,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"4sN2YPNhqKWO","outputId":"c39e963a-a2a3-45f6-be30-1d91cc8b9333"},"outputs":[{"name":"stdout","output_type":"stream","text":["RecursiveScriptModule(\n","  original_name=Model\n","  (dg): RecursiveScriptModule(original_name=DecisionGate)\n","  (linear): RecursiveScriptModule(original_name=Linear)\n",")\n","def forward(self,\n","    x: Tensor,\n","    h: Tensor) -\u003e Tuple[Tensor, Tensor]:\n","  dg = self.dg\n","  linear = self.linear\n","  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n","  new_h = torch.tanh(_0)\n","  return (new_h, new_h)\n","\n"]}],"source":["scripted_net.save('model.pt')\n","loaded_net = torch.jit.load('model.pt')\n","\n","print(loaded_net)\n","print(loaded_net.code)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4we_i9GqeZj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"PkyV8RiwrezH"},"source":["### Fun"]},{"cell_type":"markdown","metadata":{"id":"NUYWYHYIr5D1"},"source":["Python provides the unique reference counter feature, which is used for memory management. The reference counter counts the total number of references made internally in Python to assign a value to a data object. When the reference counts reach zero, the assigned memory of the object is released."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690081111177,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"VEkpFb5Oru9O","outputId":"05f45f1c-5a0f-4253-95ed-174cce43c3ff"},"outputs":[{"data":{"text/plain":["2"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["import sys\n","a = [] #1\n","sys.getrefcount(a)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690081117039,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"PsBnlLGjrzlH","outputId":"9d1df5a6-b01c-4296-a2d9-69d9c349f5b3"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["b = a\n","sys.getrefcount(a)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8093,"status":"ok","timestamp":1690086871318,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"KqpylWA9rfrI","outputId":"f4bdc3cb-7844-44d0-e099-967025c74b66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Time taken in seconds - 9.3363516330719\n"]}],"source":["import time\n","from threading import Thread\n","COUNT = 100000000\n","\n","def countdown(num):\n","    while num\u003e0:\n","        num -= 1\n","\n","start_time = time.time()\n","countdown(COUNT)\n","end_time = time.time()\n","\n","print('Time taken in seconds -', end_time - start_time)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5540,"status":"ok","timestamp":1690086876857,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"sag_UBDNrgNQ","outputId":"3ee83ff7-fc02-492a-a0fa-61a3923b6041"},"outputs":[{"name":"stdout","output_type":"stream","text":["Time taken in seconds - 6.329412937164307\n"]}],"source":["import time\n","from threading import Thread\n","\n","COUNT = 100000000\n","\n","def countdown(num):\n","    while num\u003e0:\n","        num -= 1\n","\n","thread1 = Thread(target=countdown, args=(COUNT//2,))\n","thread2 = Thread(target=countdown, args=(COUNT//2,))\n","\n","start_time = time.time()\n","thread1.start()\n","thread2.start()\n","thread1.join()\n","thread2.join()\n","end_time = time.time()\n","print('Time taken in seconds -', end_time - start_time)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8831,"status":"ok","timestamp":1690086885680,"user":{"displayName":"Rohith marktricks","userId":"06455389861066924786"},"user_tz":-330},"id":"31iZ_YFmrjuA","outputId":"c4b90817-6a67-4121-9cfd-4462396fac1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Time taken in seconds - 7.0444176197052\n"]}],"source":["from multiprocessing import Pool\n","import time\n","\n","COUNT = 100000000\n","def countdown(num):\n","    while num\u003e0:\n","        num -= 1\n","\n","if __name__ == '__main__':\n","    pool = Pool(processes=2)\n","    start_time = time.time()\n","    r1 = pool.apply_async(countdown, [COUNT//2])\n","    r2 = pool.apply_async(countdown, [COUNT//2])\n","    pool.close()\n","    pool.join()\n","    end_time = time.time()\n","    print('Time taken in seconds -', end_time - start_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GktuXwHNrnCg"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOk9SMOhnbOiKgSj4iRJMLG","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}